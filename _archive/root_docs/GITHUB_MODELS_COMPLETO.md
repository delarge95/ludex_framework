# üéØ MODELOS GITHUB - LISTA COMPLETA VERIFICADA (Nov 2025)

**Fecha**: 12 de Noviembre de 2025  
**M√©todo**: Prueba directa con API de GitHub Models  
**Total probado**: 36 modelos  
**Total disponible**: 12 modelos ‚úÖ

---

## ‚úÖ MODELOS DISPONIBLES (12 modelos)

### ü§ñ OpenAI (2 modelos)

| Modelo          | Par√°metros | Uso recomendado                                | Velocidad           |
| --------------- | ---------- | ---------------------------------------------- | ------------------- |
| **gpt-4o**      | ~200B      | **MEJOR OPCI√ìN** - An√°lisis, c√≥digo, escritura | ‚ö°‚ö°‚ö° R√°pido       |
| **gpt-4o-mini** | ~20B       | Tareas simples, prototipos                     | ‚ö°‚ö°‚ö°‚ö° Muy r√°pido |

**Recomendaci√≥n**: Usar `gpt-4o` como modelo principal para TODOS los agentes.

---

### ü¶ô Meta Llama (3 modelos)

| Modelo                           | Par√°metros | Uso recomendado                              | Velocidad           |
| -------------------------------- | ---------- | -------------------------------------------- | ------------------- |
| **Llama-3.3-70B-Instruct**       | 70B        | √öltimo Llama 3.3 - Balance calidad/velocidad | ‚ö°‚ö°‚ö° R√°pido       |
| **Meta-Llama-3.1-405B-Instruct** | **405B**   | **MODELO M√ÅS GRANDE** - Tareas complejas     | ‚ö°‚ö° Medio          |
| **Meta-Llama-3.1-8B-Instruct**   | 8B         | Tareas r√°pidas, testing                      | ‚ö°‚ö°‚ö°‚ö° Muy r√°pido |

**Recomendaci√≥n**: `Meta-Llama-3.1-405B-Instruct` es el modelo m√°s poderoso disponible GRATIS (405 mil millones de par√°metros). Alternativa seria a GPT-4o.

---

### üî¨ Microsoft Phi (1 modelo)

| Modelo    | Par√°metros | Uso recomendado                   | Velocidad     |
| --------- | ---------- | --------------------------------- | ------------- |
| **Phi-4** | ~14B       | √öltimo Phi - C√≥digo, razonamiento | ‚ö°‚ö°‚ö° R√°pido |

**Recomendaci√≥n**: Excelente para generaci√≥n de c√≥digo y tareas t√©cnicas.

---

### üåü Mistral AI (2 modelos)

| Modelo            | Par√°metros | Uso recomendado           | Velocidad           |
| ----------------- | ---------- | ------------------------- | ------------------- |
| **Mistral-Nemo**  | 12B        | Balance calidad/velocidad | ‚ö°‚ö°‚ö° R√°pido       |
| **Mistral-small** | 7B         | Tareas r√°pidas            | ‚ö°‚ö°‚ö°‚ö° Muy r√°pido |

**Recomendaci√≥n**: Buenos para tareas generales si hay rate limits con GPT-4o.

---

### üî∑ Cohere (2 modelos)

| Modelo                            | Par√°metros | Uso recomendado             | Velocidad     |
| --------------------------------- | ---------- | --------------------------- | ------------- |
| **cohere-command-r-08-2024**      | ~35B       | Tareas generales, RAG       | ‚ö°‚ö°‚ö° R√°pido |
| **cohere-command-r-plus-08-2024** | ~104B      | An√°lisis complejo, s√≠ntesis | ‚ö°‚ö° Medio    |

**Recomendaci√≥n**: `cohere-command-r-plus-08-2024` excelente para s√≠ntesis de contenido (Agent 5).

---

### üéØ AI21 Labs (1 modelo)

| Modelo              | Par√°metros | Uso recomendado                         | Velocidad  |
| ------------------- | ---------- | --------------------------------------- | ---------- |
| **jamba-1.5-large** | ~94B       | H√≠brido SSM-Transformer, contexto largo | ‚ö°‚ö° Medio |

**Recomendaci√≥n**: Bueno para documentos largos (papers acad√©micos).

---

### üöÄ Otras Opciones (1 modelo)

| Modelo           | Par√°metros | Uso recomendado             | Velocidad          |
| ---------------- | ---------- | --------------------------- | ------------------ |
| **ministral-3b** | 3B         | Testing, prototipos r√°pidos | ‚ö°‚ö°‚ö°‚ö°‚ö° Extremo |

---

## ‚ùå MODELOS NO DISPONIBLES

### Anthropic Claude

- ‚ùå claude-3-5-sonnet
- ‚ùå claude-3-opus
- ‚ùå claude-3-sonnet
- ‚ùå claude-3-haiku

**Nota**: Ninguna versi√≥n de Claude est√° disponible en GitHub Models actualmente.

### OpenAI o1

- ‚ùå o1-preview (error en API)
- ‚ùå o1-mini (error en API)

### Otros Llama

- ‚ùå Meta-Llama-3.1-70B-Instruct (usa Llama-3.3-70B en su lugar)
- ‚ùå Meta-Llama-3-70B-Instruct
- ‚ùå Meta-Llama-3-8B-Instruct

### Otros Phi

- ‚ùå Phi-3.5-\* (todas las versiones)
- ‚ùå Phi-3-\* (todas las versiones)

---

## üèÜ TOP 3 MODELOS RECOMENDADOS PARA TU TFG

### 1Ô∏è‚É£ **gpt-4o** (OpenAI)

**Por qu√©**:

- ‚úÖ Mejor calidad general
- ‚úÖ Excelente para c√≥digo, an√°lisis, escritura
- ‚úÖ Balance perfecto calidad/velocidad
- ‚úÖ Usado por empresas en producci√≥n

**Usar para**: TODOS los agentes (1, 2, 3, 4, 5)

---

### 2Ô∏è‚É£ **Meta-Llama-3.1-405B-Instruct** (Meta)

**Por qu√©**:

- ‚úÖ **405 mil millones de par√°metros** (modelo m√°s grande)
- ‚úÖ Open source (puedes citarlo en TFG)
- ‚úÖ Compite con GPT-4o en benchmarks
- ‚úÖ Gratis sin l√≠mites ocultos

**Usar para**: Alternativa cuando GPT-4o tenga rate limits

---

### 3Ô∏è‚É£ **cohere-command-r-plus-08-2024** (Cohere)

**Por qu√©**:

- ‚úÖ Excelente para s√≠ntesis de contenido
- ‚úÖ Bueno para RAG (Retrieval Augmented Generation)
- ‚úÖ Optimizado para tareas de escritura

**Usar para**: Agent 5 (Content Synthesizer) si necesitas diversificar

---

## üí° ESTRATEGIA RECOMENDADA

### Opci√≥n A: Todo con GPT-4o (m√°s simple)

```python
# Todos los agentes
model = "gpt-4o"
```

**Ventajas**:

- ‚úÖ M√°xima calidad
- ‚úÖ Consistencia entre agentes
- ‚úÖ M√°s f√°cil de debuggear

**Desventajas**:

- ‚ö†Ô∏è Rate limits (~100-200 req/hora)

---

### Opci√≥n B: Multi-modelo (m√°s robusto)

```python
# Agent 1: Niche Analyst
model = "gpt-4o"

# Agent 2: Literature Researcher
model = "Meta-Llama-3.1-405B-Instruct"  # Mejor para papers largos

# Agent 3: Technical Architect
model = "gpt-4o"

# Agent 4: Implementation Specialist
model = "Phi-4"  # Especializado en c√≥digo

# Agent 5: Content Synthesizer
model = "cohere-command-r-plus-08-2024"  # Mejor para escritura
```

**Ventajas**:

- ‚úÖ Distribuye rate limits
- ‚úÖ Usa fortalezas de cada modelo
- ‚úÖ M√°s robusto ante fallos

**Desventajas**:

- ‚ö†Ô∏è M√°s complejo de configurar
- ‚ö†Ô∏è Resultados pueden variar entre agentes

---

## üß™ C√ìMO PROBAR LOS MODELOS

### Probar un modelo espec√≠fico:

```python
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(
    base_url="https://models.inference.ai.azure.com",
    api_key=os.getenv("GITHUB_TOKEN"),
)

# Cambiar el modelo aqu√≠
response = client.chat.completions.create(
    model="Meta-Llama-3.1-405B-Instruct",  # o cualquier otro
    messages=[
        {"role": "user", "content": "Explica qu√© son los agentes aut√≥nomos"}
    ],
    max_tokens=500,
)

print(response.choices[0].message.content)
```

### Script para comparar modelos:

```bash
python discover_github_models.py
```

---

## üìä COMPARACI√ìN CON OTROS SERVICIOS

| Servicio  | Modelo similar    | Costo              | GitHub Models                |
| --------- | ----------------- | ------------------ | ---------------------------- |
| OpenAI    | GPT-4o            | $5-15/1M tokens    | **GRATIS** ‚úÖ                |
| Anthropic | Claude Sonnet 4.5 | $3-15/1M tokens    | ‚ùå No disponible             |
| Meta      | Llama 3.1-405B    | Gratis (self-host) | **GRATIS** ‚úÖ (no self-host) |
| Cohere    | Command R+        | $3-15/1M tokens    | **GRATIS** ‚úÖ                |
| AI21      | Jamba 1.5         | $0.2-8/1M tokens   | **GRATIS** ‚úÖ                |

**Conclusi√≥n**: GitHub Models te da acceso GRATIS a modelos que costar√≠an $50-100/mes en otros servicios.

---

## üöÄ PR√ìXIMOS PASOS

1. ‚úÖ **Ya tienes configurado**: GitHub Token + Perplexity API
2. ‚èπÔ∏è **Siguiente**: Integrar modelos en los agentes
3. ‚èπÔ∏è **Despu√©s**: Probar pipeline completo
4. ‚èπÔ∏è **Finalmente**: Optimizar qu√© modelo usar en cada agente

---

## üìö SCRIPTS DISPONIBLES

```bash
# Ver todos los modelos disponibles
python discover_github_models.py

# Probar acceso r√°pido
python test_github_models_env.py

# Listar modelos con detalles
python list_github_models.py
```

---

## ‚úÖ RESUMEN EJECUTIVO

**Total verificado**: 36 modelos  
**Total disponible**: 12 modelos (33% de lo probado)  
**Mejor modelo**: `gpt-4o` (OpenAI)  
**Modelo m√°s grande**: `Meta-Llama-3.1-405B-Instruct` (405B par√°metros)  
**Costo**: **GRATIS** durante beta  
**Rate limit**: ~100-200 requests/hora

**Conclusi√≥n**: Tienes acceso a modelos de nivel enterprise completamente gratis. Usa `gpt-4o` como principal y `Meta-Llama-3.1-405B-Instruct` como backup.
