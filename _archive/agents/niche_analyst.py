"""
NicheAnalyst Agent - First agent in the ARA pipeline.

Este agente:
1. Recibe un niche/tema de investigaciÃ³n
2. Identifica tendencias emergentes en el niche
3. Analiza comunidades (Reddit, GitHub, foros, blogs)
4. EvalÃºa viabilidad y demanda del mercado
5. Genera keywords y sub-niches para exploraciÃ³n profunda

Modelos:
- Primary: Gemini 2.5 Pro (free, 1500 req/dÃ­a, 15 RPM)
- Fallback: MiniMax-M2 (free beta)

SLA: 7-8 minutos
Budget: 0 crÃ©ditos (ambos modelos son gratuitos)

Tools: scraping_tool (scrape_website, scrape_multiple_urls), 
       search_tool (search_recent_papers)

Output: Reporte Markdown con:
- Viabilidad del niche (score 1-10)
- Tendencias identificadas (3-5)
- Comunidades activas (links + estadÃ­sticas)
- Keywords principales (10-15)
- Sub-niches sugeridos (2-3)
- Demanda estimada (score 1-10)

Fuente: docs/03_AI_MODELS.md (Agent 1), docs/04_ARCHITECTURE.md (Agents Layer)
"""
import structlog
# from crewai import Agent, Task  # CrewAI removed - using LangGraph only
from typing import Dict, Any

from config.settings import settings
from tools import get_scraping_tool, get_search_tool

logger = structlog.get_logger()


def create_niche_analyst_agent() -> Agent:
    """
    Crea el agente NicheAnalyst.
    
    Este agente es el primero en ejecutarse y su output alimenta
    a los demÃ¡s agentes del pipeline.
    
    Returns:
        Agent: Instancia configurada del NicheAnalyst
    """
    # Obtener tools
    scraping_tool = get_scraping_tool()
    search_tool = get_search_tool()
    
    # Configurar LLM (Groq - LLaMA 3.3-70B GRATIS)
    llm_model = "groq/llama-3.3-70b-versatile"
    
    agent = Agent(
        role="Niche Market Analyst",
        
        goal="""Analizar la viabilidad y oportunidades del niche '{niche}' mediante:
        1. BÃºsqueda de papers recientes en Semantic Scholar (Ãºltimos 2 aÃ±os)
        2. Scraping de comunidades activas (GitHub repos, Reddit threads, blogs)
        3. IdentificaciÃ³n de tendencias emergentes y gaps
        4. EvaluaciÃ³n de demanda y competencia
        5. GeneraciÃ³n de keywords y sub-niches para profundizaciÃ³n
        """,
        
        backstory="""Eres un analista de mercado especializado en nichos tecnolÃ³gicos emergentes.
        Tienes 10+ aÃ±os de experiencia identificando oportunidades en intersecciones de tecnologÃ­as.
        
        Tu expertise incluye:
        - AnÃ¡lisis de trends en GitHub (stars, forks, recent activity)
        - EvaluaciÃ³n de comunidades en Reddit, HackerNews, dev.to
        - IdentificaciÃ³n de papers acadÃ©micos relevantes (Semantic Scholar)
        - DetecciÃ³n de gaps entre teorÃ­a acadÃ©mica y prÃ¡ctica industrial
        - GeneraciÃ³n de keywords optimizadas para bÃºsqueda profunda
        
        Tu misiÃ³n es validar si el niche es viable (suficiente interÃ©s, comunidad activa,
        investigaciÃ³n acadÃ©mica, pero no oversaturado) y generar una hoja de ruta para
        los siguientes agentes.
        
        IMPORTANTE: 
        - Usa scraping_tool para buscar en GitHub, Reddit, blogs
        - Usa search_tool para encontrar papers recientes (Ãºltimos 2 aÃ±os)
        - EnfÃ³cate en TENDENCIAS EMERGENTES, no en tecnologÃ­as maduras
        - SÃ© crÃ­tico: si el niche no es viable, indÃ­calo claramente
        """,
        
        tools=[
            # Web scraping (10 req/min rate limit)
            scraping_tool.scrape_website,
            scraping_tool.scrape_multiple_urls,
            
            # Academic search (1 req/seg CRITICAL rate limit)
            search_tool.search_recent_papers,
        ],
        
        llm=llm_model,  # String del modelo en formato litellm
        
        verbose=True,  # Logs detallados
        memory=True,   # Recuerda contexto entre tareas
        allow_delegation=False,  # No delega a otros agentes (es el primero)
        max_iter=15,   # MÃ¡ximo 15 iteraciones de tool usage
        max_rpm=15,    # Gemini free tier: 15 RPM
    )
    
    logger.info(
        "niche_analyst_created",
        model="gemini-2.5-pro",
        tools_count=3,
        max_rpm=15,
    )
    
    return agent


def create_niche_analysis_task(agent: Agent, niche: str) -> Task:
    """
    Crea la tarea de anÃ¡lisis de niche.
    
    Args:
        agent: Instancia del NicheAnalyst
        niche: Nombre del niche a analizar (ej: "Rust + WebAssembly")
    
    Returns:
        Task: Tarea configurada con descripciÃ³n y output esperado
    """
    task = Task(
        description="""
        Analiza el niche "__NICHE__" siguiendo estos pasos:
        
        **PASO 1: BÃºsqueda AcadÃ©mica Inicial (2-3 minutos)**
    - Usa search_recent_papers("__NICHE__", limit=20, years_back=2)
        - Identifica: Â¿Hay investigaciÃ³n activa? Â¿CuÃ¡ntos papers en Ãºltimos 2 aÃ±os?
        - Â¿QuÃ© subtemas estÃ¡n en auge? (analiza tÃ­tulos y abstracts)
        
        **PASO 2: AnÃ¡lisis de Comunidades (3-4 minutos)**
    - GitHub: Scrape "https://github.com/search?q=__NICHE__&type=repositories"
          â†’ Identifica repos con >500 stars creados en Ãºltimos 2 aÃ±os
          â†’ Analiza activity (commits recientes, issues activos)
        
    - Reddit: Scrape "https://www.reddit.com/search/?q=__NICHE__"
          â†’ Busca subreddits activos relacionados
          â†’ Analiza cantidad de posts recientes
        
        - Dev.to/Medium: Scrape artÃ­culos recientes sobre el niche
          â†’ Â¿Hay hype? Â¿O es un tema muerto?
        
        **PASO 3: IdentificaciÃ³n de Trends (1-2 minutos)**
        - Compara papers acadÃ©micos vs repos GitHub
        - Â¿Hay gaps entre teorÃ­a y prÃ¡ctica?
        - Â¿QuÃ© problemas estÃ¡n sin resolver?
        - Â¿QuÃ© tecnologÃ­as complementarias estÃ¡n emergiendo?
        
        **PASO 4: EvaluaciÃ³n de Viabilidad (1 minuto)**
        - Â¿Hay suficiente interÃ©s? (score 1-10)
        - Â¿Hay demanda real? (evidencia: jobs, startups, funding)
        - Â¿EstÃ¡ oversaturado? (demasiada competencia)
        - Â¿Es tendencia pasajera o duradera?
        
        **PASO 5: GeneraciÃ³n de Keywords y Sub-niches**
        - Keywords principales (10-15) para bÃºsqueda profunda
        - Sub-niches especÃ­ficos (2-3) para exploraciÃ³n
        - Queries optimizadas para Semantic Scholar
        
        IMPORTANTE:
        - Respeta rate limits: Semantic Scholar = 1 req/seg, Scraping = 10 req/min
        - Si el scraping falla (anti-bot), usa informaciÃ³n de papers
        - SÃ© honesto: si el niche no es viable, di por quÃ©
        - Prioriza CALIDAD sobre cantidad (mejor 5 insights buenos que 20 vagos)
    """.replace("__NICHE__", niche),

    expected_output="""
    # AnÃ¡lisis de Niche: __NICHE__
        
        ## 1. Resumen Ejecutivo (2-3 pÃ¡rrafos)
        - Â¿QuÃ© es este niche? (definiciÃ³n clara en 1-2 oraciones)
        - Â¿Por quÃ© es relevante ahora? (trends, timing)
        - Veredicto: Â¿Es viable para investigaciÃ³n profunda? (SÃ/NO + justificaciÃ³n)
        
        ## 2. Viabilidad General
        - **Score de Viabilidad**: X/10 (justificar)
        - **Score de Demanda**: X/10 (evidencia: jobs, startups, repos activos)
        - **Score de Competencia**: X/10 (1=poco competido, 10=oversaturado)
        - **Tendencia**: â¬†ï¸ Creciendo | â¡ï¸ Estable | â¬‡ï¸ Declinando
        
        ## 3. InvestigaciÃ³n AcadÃ©mica
        - **Papers encontrados**: X papers en Ãºltimos 2 aÃ±os
        - **Top 3-5 papers mÃ¡s citados**: (tÃ­tulo, aÃ±o, citaciones, insight clave)
        - **Subtemas emergentes**: (3-5 subtemas con >3 papers cada uno)
        - **Gaps identificados**: (2-3 problemas sin resolver o poco explorados)
        
        ## 4. Comunidades y Ecosistema
        ### GitHub
        - **Repos relevantes**: (Top 3-5 con >500 stars, actividad reciente)
        - **Actividad**: (commits/mes, issues abiertos, contributors activos)
        - **Tech Stack comÃºn**: (lenguajes, frameworks mÃ¡s usados)
        
        ### Reddit/Foros
        - **Subreddits activos**: (nombre, subscribers, posts/mes)
        - **Discusiones recientes**: (temas hot, preguntas frecuentes)
        
        ### Blogs/ArtÃ­culos
        - **ArtÃ­culos tÃ©cnicos**: (links a Medium, dev.to, blogs corporativos)
        - **Tutoriales**: Â¿Hay contenido educativo de calidad?
        
        ## 5. Tendencias Identificadas
        1. **Trend 1**: (nombre + descripciÃ³n 2-3 lÃ­neas + evidencia)
        2. **Trend 2**: (nombre + descripciÃ³n 2-3 lÃ­neas + evidencia)
        3. **Trend 3**: (nombre + descripciÃ³n 2-3 lÃ­neas + evidencia)
        
        ## 6. Keywords Principales (para LiteratureResearcher)
        ### Keywords Primarias (5-7):
    - "__NICHE__"
        - [keyword 2]
        - [keyword 3]
        - ...
        
        ### Keywords Secundarias (5-8):
        - [keyword combinada 1]
        - [keyword combinada 2]
        - ...
        
        ## 7. Sub-niches Sugeridos
        ### Sub-niche 1: [Nombre]
        - DescripciÃ³n: [2-3 lÃ­neas]
        - Viabilidad: X/10
        - RazÃ³n: [por quÃ© es interesante]
        
        ### Sub-niche 2: [Nombre]
        - DescripciÃ³n: [2-3 lÃ­neas]
        - Viabilidad: X/10
        - RazÃ³n: [por quÃ© es interesante]
        
        ## 8. Recomendaciones para Siguiente Agente (LiteratureResearcher)
        - **Enfocar bÃºsqueda en**: [subtemas especÃ­ficos]
        - **Priorizar papers con**: [caracterÃ­sticas: citaciones, aÃ±o, venues]
        - **Explorar intersecciones**: [niche + X, niche + Y]
        - **Queries Semantic Scholar sugeridas**: (3-5 queries optimizadas)
        
        ## 9. Alertas y Consideraciones
        - âš ï¸ [Cualquier limitaciÃ³n encontrada: anti-bot, rate limits, etc.]
        - ğŸ’¡ [Insights adicionales no cubiertos arriba]
        - ğŸš« [Red flags si los hay: hype sin sustancia, comunidad tÃ³xica, etc.]
    """.replace("__NICHE__", niche),
        
        agent=agent,
        
        # Este es el primer task, no tiene contexto previo
        context=[],
    )
    
    logger.info(
        "niche_analysis_task_created",
        niche=niche,
        expected_duration="7-8 minutes",
        tools_used=["scraping_tool", "search_tool"],
    )
    
    return task


# FunciÃ³n helper para crear agent + task juntos
def create_niche_analyst(niche: str) -> tuple[Agent, Task]:
    """
    Helper para crear el NicheAnalyst con su tarea.
    
    Args:
        niche: Nombre del niche a analizar
    
    Returns:
        tuple[Agent, Task]: Tupla (agente, tarea)
    
    Example:
        >>> agent, task = create_niche_analyst("Rust + WebAssembly")
        >>> crew = Crew(agents=[agent], tasks=[task])
        >>> result = graph.invoke()
    """
    agent = create_niche_analyst_agent()
    task = create_niche_analysis_task(agent, niche)
    return agent, task
