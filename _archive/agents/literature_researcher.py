"""
LiteratureResearcher Agent - Deep academic literature analysis.

Este agente:
1. Recibe keywords del NicheAnalyst
2. Realiza bÃºsqueda profunda en Semantic Scholar (100-200 papers)
3. Descarga y procesa PDFs de papers crÃ­ticos (20-30 PDFs)
4. Analiza citaciones, trends, y metodologÃ­as
5. Identifica gaps en la investigaciÃ³n actual
6. Guarda papers en base de datos para referencia futura

Modelos:
- Primary: GPT-5 (1 crÃ©dito, mejor comprensiÃ³n de papers acadÃ©micos)
- Fallback: Claude Haiku 4.5 (0.33 crÃ©ditos, rÃ¡pido y barato)

SLA: 20-25 minutos (BOTTLENECK debido a rate limit de Semantic Scholar 1 req/seg)
Budget: ~0.15 crÃ©ditos con cache hits, ~1.5 sin cache

OPTIMIZACIÃ“N CRÃTICA:
- Usa search_papers_parallel con offsets para mitigar bottleneck
- Cache agresivo (7 dÃ­as) en Redis para papers
- Prioriza papers con >10 citaciones y aÃ±o >2020

Tools: search_tool (todos: 5 tools), pdf_tool (4 tools), database_tool (3 tools)

Output: Base de conocimiento con 50-100 papers procesados, anÃ¡lisis de trends

Fuente: docs/03_AI_MODELS.md (Agent 2), docs/04_ARCHITECTURE.md (Agents Layer)
"""
import structlog
# from crewai import Agent, Task  # CrewAI removed - using LangGraph only
from typing import Dict, Any, Optional

from config.settings import settings
from tools import get_search_tool, get_pdf_tool, get_database_tool

logger = structlog.get_logger()


def create_literature_researcher_agent() -> Agent:
    """
    Crea el agente LiteratureResearcher.
    
    Este agente es el mÃ¡s intensivo en tiempo debido al rate limit
    de Semantic Scholar (1 req/seg). Usa bÃºsqueda paralela para mitigar.
    
    Returns:
        Agent: Instancia configurada del LiteratureResearcher
    """
    # Obtener tools
    search_tool = get_search_tool()
    pdf_tool = get_pdf_tool()
    database_tool = get_database_tool()
    
    # Configurar LLM (Groq - LLaMA 3.3-70B GRATIS)
    llm_model = "groq/llama-3.3-70b-versatile"
    
    agent = Agent(
        role="Academic Literature Researcher",
        
        goal="""Realizar investigaciÃ³n profunda en literatura acadÃ©mica sobre '{niche}':
        1. BÃºsqueda exhaustiva en Semantic Scholar (100-200 papers)
        2. AnÃ¡lisis de citaciones y trends (papers mÃ¡s influyentes)
        3. Descarga y procesamiento de PDFs crÃ­ticos (20-30 papers)
        4. IdentificaciÃ³n de metodologÃ­as comunes y gaps
        5. ConstrucciÃ³n de knowledge base persistente en Supabase
        6. GeneraciÃ³n de insights accionables para arquitectura tÃ©cnica
        """,
        
        backstory="""Eres un investigador acadÃ©mico PhD en Computer Science con 15 aÃ±os de experiencia.
        
        Tu expertise incluye:
        - BÃºsqueda sistemÃ¡tica en bases acadÃ©micas (Semantic Scholar, arXiv)
        - AnÃ¡lisis de citaciones y redes de papers (bibliometrÃ­a)
        - Lectura rÃ¡pida de papers: Abstract â†’ Introduction â†’ Conclusion â†’ Methods
        - IdentificaciÃ³n de metodologÃ­as reproducibles vs experimentales
        - DetecciÃ³n de trends emergentes antes de que sean mainstream
        - EvaluaciÃ³n crÃ­tica de calidad de investigaciÃ³n (venue, citaciones, reproducibilidad)
        
        Tu proceso de trabajo:
        1. **BÃºsqueda EstratÃ©gica**: Empiezas con keywords broad, luego refinas
        2. **Filtrado Inteligente**: Priorizas papers con >10 citaciones, venues top-tier
        3. **AnÃ¡lisis en Profundidad**: Lees 20-30 papers crÃ­ticos (no solo abstracts)
        4. **SÃ­ntesis**: Identificas patterns, metodologÃ­as comunes, y gaps
        5. **Persistencia**: Guardas TODOS los papers en base de datos para futura referencia
        
        OPTIMIZACIONES CRÃTICAS (para cumplir SLA de 25 minutos):
        - Usa search_papers_parallel con 5 offsets simultÃ¡neos (mitiga bottleneck de 1 req/seg)
        - Cache hits = 7 dÃ­as en Redis (si el niche ya fue analizado, retorna cache)
        - Descarga PDFs solo de top 20-30 papers (no los 200)
        - Extrae solo Abstract + Introduction + Methods de PDFs (skip Results/Discussion)
        
        MANEJO DE RATE LIMITS:
        - Semantic Scholar: 1 req/seg (CRÃTICO) â†’ Usa parallel search con offsets
        - Si hit rate limit 429: espera 60 segundos automÃ¡ticamente (circuit breaker)
        - PDFs: 5 conversions/min (MarkItDown) â†’ Procesa en batches de 5
        
        IMPORTANTE:
        - NO uses search_academic_papers bÃ¡sico (toma 200 segundos para 200 papers)
        - USA search_papers_parallel (toma 40-50 segundos para 200 papers)
        - Guarda papers en DB ANTES de descargar PDFs (para reanudar si falla)
        """,
        
        tools=[
            # Academic search (BOTTLENECK - 1 req/seg)
            search_tool.search_academic_papers,  # BÃºsqueda bÃ¡sica
            search_tool.search_papers_parallel,  # USAR ESTO (parallel con offsets)
            search_tool.get_paper_details,       # Detalles de paper especÃ­fico
            search_tool.get_related_papers,      # Recommendations/citations
            search_tool.search_recent_papers,    # Papers recientes sorted by citations
            
            # PDF processing (5 conversions/min)
            pdf_tool.convert_pdf_to_markdown,    # ConversiÃ³n completa
            pdf_tool.extract_pdf_sections,       # Solo secciones especÃ­ficas
            pdf_tool.extract_pdf_text_only,      # Solo texto (para bÃºsquedas)
            pdf_tool.convert_multiple_pdfs,      # Batch conversion
            
            # Database persistence
            database_tool.save_paper,            # Guardar paper individual
            database_tool.query_papers,          # Buscar papers guardados
            database_tool.get_paper_by_id,       # Retrieve by Semantic Scholar ID
        ],
        
        llm=llm_model,
        
        verbose=True,
        memory=True,
        allow_delegation=False,
        max_iter=30,  # MÃ¡s iteraciones (proceso largo)
        max_rpm=60,   # GPT-5 via Copilot no tiene rate limit estricto
    )
    
    logger.info(
        "literature_researcher_created",
        model="gpt-5",
        fallback="claude-haiku-4.5",
        tools_count=12,
        estimated_duration="20-25 minutes",
        bottleneck="semantic_scholar_rate_limit",
    )
    
    return agent


def create_literature_research_task(
    agent: Agent, 
    niche: str,
    niche_analysis_context: Optional[Task] = None
) -> Task:
    """
    Crea la tarea de investigaciÃ³n literaria.
    
    Args:
        agent: Instancia del LiteratureResearcher
        niche: Nombre del niche
        niche_analysis_context: Task del NicheAnalyst (para recibir keywords)
    
    Returns:
        Task: Tarea configurada con descripciÃ³n y output esperado
    """
    task = Task(
        description="""
        Realiza investigaciÃ³n profunda en literatura acadÃ©mica sobre "__NICHE__".
        
        Recibes del NicheAnalyst:
        - Keywords principales (5-7)
        - Keywords secundarias (5-8)
        - Sub-niches sugeridos (2-3)
        - Queries optimizadas para Semantic Scholar
        
        **FASE 1: BÃºsqueda Exhaustiva (8-10 minutos)**
        
        PASO 1.1: BÃºsqueda Paralela Inicial (3-4 min)
        - USA search_papers_parallel() con keywords principales
        - Busca 200 papers en total (5 queries paralelas Ã— 40 papers cada una)
        - Offsets: [0, 40, 80, 120, 160] â†’ Total 200 papers en ~40 segundos
        - Filtra por: year >= 2020, citations >= 10
        
        PASO 1.2: AnÃ¡lisis de Papers Top (2-3 min)
        - Ordena los 200 papers por citaciones (descendente)
        - Identifica los Top 50 papers mÃ¡s citados
        - Para cada uno: analiza Abstract (ya incluido en response)
        - Categoriza por subtemas usando keywords
        
        PASO 1.3: ExpansiÃ³n con Related Papers (3 min)
        - Selecciona Top 5 papers mÃ¡s citados
        - Para cada uno: get_related_papers() â†’ 10 recommendations
        - Agrega papers Ãºnicos (sin duplicados) â†’ +30-40 papers
        - Total: ~200-240 papers identificados
        
        PASO 1.4: Persistencia en Base de Datos (2 min)
        - Guarda TODOS los papers en Supabase usando save_paper()
        - Batch insert (no uno por uno) para eficiencia
        - Esto permite:
          a) Consultas futuras sin re-scrapear Semantic Scholar
          b) AnÃ¡lisis de trends a lo largo del tiempo
          c) Compartir knowledge base entre anÃ¡lisis
        
        **FASE 2: AnÃ¡lisis en Profundidad (10-12 minutos)**
        
        PASO 2.1: SelecciÃ³n de Papers CrÃ­ticos (1 min)
        - De los 200-240 papers, selecciona Top 25 para lectura profunda
        - Criterios:
          a) Citaciones > 20 (papers influyentes)
          b) AÃ±o 2022-2024 (investigaciÃ³n reciente)
          c) Venues top: ACL, NeurIPS, ICML, CVPR, ICLR, etc.
          d) Diversidad: cubrir todos los subtemas identificados
        
        PASO 2.2: Descarga y Procesamiento de PDFs (8-10 min)
        - Descarga PDFs de los 25 papers seleccionados
        - USA convert_multiple_pdfs() con max_concurrent=5 (respeta rate limit)
        - Si PDF no disponible: usa extract_pdf_text_only() como fallback
        - Extrae SOLO: Abstract, Introduction, Methods, Conclusion
        - Skip: Results, Discussion, References (ahorran tiempo)
        - Batch de 5 papers Ã— 5 batches = 25 papers en ~10 min
        
        PASO 2.3: AnÃ¡lisis de MetodologÃ­as (1 min)
        - Identifica metodologÃ­as comunes en los 25 papers
        - Categoriza: experimental, theoretical, survey, implementation
        - Â¿QuÃ© datasets usan? Â¿QuÃ© benchmarks?
        - Â¿QuÃ© mÃ©tricas de evaluaciÃ³n?
        
        **FASE 3: SÃ­ntesis y Gaps (2-3 minutos)**
        
        PASO 3.1: AnÃ¡lisis de Trends (1 min)
        - Compara papers 2020-2021 vs 2022-2024
        - Â¿QuÃ© ha cambiado? Â¿QuÃ© estÃ¡ emergiendo?
        - Â¿Hay shifts en paradigmas? (ej: de RNNs a Transformers)
        
        PASO 3.2: IdentificaciÃ³n de Gaps (1 min)
        - Â¿QuÃ© problemas estÃ¡n sin resolver?
        - Â¿QuÃ© Ã¡reas tienen pocos papers (<5)?
        - Â¿Hay discrepancias entre papers? (findings contradictorios)
        - Â¿QuÃ© intersecciones no se han explorado?
        
        PASO 3.3: GeneraciÃ³n de Insights (1 min)
        - 3-5 insights clave para TechnicalArchitect
        - Recomendaciones de arquitecturas tÃ©cnicas basadas en papers
        - TecnologÃ­as/frameworks mencionados frecuentemente
        - Datasets pÃºblicos disponibles para experimentaciÃ³n
        
        **MANEJO DE ERRORES Y OPTIMIZACIONES**:
        - Si Semantic Scholar retorna 429 (rate limit): espera 60 seg automÃ¡ticamente
        - Si PDF download falla: continÃºa con los demÃ¡s (no bloqueante)
        - Si cache hit en Redis: skip bÃºsqueda (retorna papers guardados)
        - Si ya hay papers en DB para este niche: complementa (no duplica)
        
        **OUTPUTS INTERMEDIOS** (para logs):
        - DespuÃ©s de FASE 1: "Encontrados X papers, Top 10: [tÃ­tulos]"
        - DespuÃ©s de FASE 2: "Procesados Y PDFs, Z fallaron"
        - DespuÃ©s de FASE 3: "Identificados N gaps, M trends"
    """.replace("__NICHE__", niche),

    expected_output="""
    # InvestigaciÃ³n Literaria: __NICHE__
        
        ## 1. Resumen Ejecutivo (3-4 pÃ¡rrafos)
        - Â¿QuÃ© encontramos? (hallazgos principales en 2-3 oraciones)
        - Â¿CuÃ¡l es el estado del arte actual? (descripciÃ³n general)
        - Â¿QuÃ© gaps son mÃ¡s prometedores? (2-3 oportunidades clave)
        - ConclusiÃ³n: Â¿Hay suficiente investigaciÃ³n para continuar? (SÃ/NO + justificaciÃ³n)
        
        ## 2. EstadÃ­sticas de BÃºsqueda
        - **Papers encontrados**: X papers (total en Semantic Scholar)
        - **Papers analizados**: Y papers (despuÃ©s de filtros)
        - **Papers guardados en DB**: Z papers (persistidos en Supabase)
        - **PDFs procesados**: W papers (lectura profunda)
        - **Tiempo total**: XX minutos YY segundos
        - **Cache hits**: N queries (si aplica)
        
        ## 3. Papers MÃ¡s Influyentes (Top 10)
        Para cada paper:
        ### Paper 1: [TÃ­tulo]
        - **Autores**: [nombres]
        - **AÃ±o**: YYYY
        - **Venue**: [conferencia/journal]
        - **Citaciones**: XXX
        - **Semantic Scholar ID**: [id para referencia]
        - **Insight clave** (1-2 lÃ­neas): [quÃ© aporta este paper]
        - **MetodologÃ­a**: [experimental/theoretical/survey/implementation]
        - **URL**: [link a paper]
        
        [Repetir para Top 10]
        
        ## 4. AnÃ¡lisis por Subtemas
        ### Subtema 1: [Nombre]
        - **Papers encontrados**: X papers
        - **Trend**: â¬†ï¸ Creciendo | â¡ï¸ Estable | â¬‡ï¸ Declinando
        - **Papers clave**: [3-5 papers mÃ¡s citados]
        - **MetodologÃ­as comunes**: [lista]
        - **Gaps identificados**: [2-3 problemas sin resolver]
        
        ### Subtema 2: [Nombre]
        [Misma estructura]
        
        ### Subtema 3: [Nombre]
        [Misma estructura]
        
        ## 5. MetodologÃ­as y TecnologÃ­as
        ### MetodologÃ­as Comunes (3-5)
        1. **[MetodologÃ­a 1]**: Usada en X papers
           - DescripciÃ³n: [2-3 lÃ­neas]
           - Papers representativos: [links]
           - Limitaciones conocidas: [1-2 lÃ­neas]
        
        ### TecnologÃ­as/Frameworks Frecuentes
        - **[Tech 1]**: Mencionada en X papers (ej: PyTorch, TensorFlow)
        - **[Tech 2]**: Mencionada en Y papers
        - **[Tech 3]**: Mencionada en Z papers
        
        ### Datasets PÃºblicos Disponibles
        - **[Dataset 1]**: [DescripciÃ³n 1 lÃ­nea] | Usado en X papers | [Link]
        - **[Dataset 2]**: [DescripciÃ³n 1 lÃ­nea] | Usado en Y papers | [Link]
        
        ### Benchmarks EstÃ¡ndar
        - **[Benchmark 1]**: [MÃ©trica] | Usado en X papers
        - **[Benchmark 2]**: [MÃ©trica] | Usado en Y papers
        
        ## 6. AnÃ¡lisis Temporal de Trends
        ### EvoluciÃ³n 2020-2024
        - **2020-2021**: [QuÃ© se investigaba] | X papers
        - **2022-2023**: [Shift en enfoque] | Y papers
        - **2024**: [Estado actual] | Z papers
        
        ### Trends Emergentes (3-5)
        1. **[Trend 1]**: [DescripciÃ³n 2-3 lÃ­neas]
           - Evidencia: X papers en Ãºltimos 6 meses
           - Papers clave: [links]
           - PredicciÃ³n: [hacia dÃ³nde va]
        
        2. **[Trend 2]**: [DescripciÃ³n 2-3 lÃ­neas]
           [Misma estructura]
        
        ## 7. Gaps en la InvestigaciÃ³n (CRÃTICO para arquitectura)
        ### Gap 1: [Nombre del Gap]
        - **DescripciÃ³n**: [3-4 lÃ­neas: quÃ© falta, por quÃ© importa]
        - **Evidencia**: Solo X papers abordan esto (vs Y esperados)
        - **Oportunidad**: [CÃ³mo se podrÃ­a resolver]
        - **Complejidad**: Baja | Media | Alta
        - **Impacto potencial**: Bajo | Medio | Alto
        
        ### Gap 2: [Nombre del Gap]
        [Misma estructura]
        
        ### Gap 3: [Nombre del Gap]
        [Misma estructura]
        
        ## 8. Discrepancias y Controversias
        - Â¿Hay findings contradictorios? (Paper A dice X, Paper B dice Y)
        - Â¿Hay debates abiertos en la comunidad?
        - Â¿QuÃ© metodologÃ­as estÃ¡n siendo cuestionadas?
        
        ## 9. Recomendaciones para TechnicalArchitect
        ### Arquitecturas TÃ©cnicas Sugeridas (basadas en papers)
        1. **[Arquitectura 1]**: [DescripciÃ³n]
           - Papers que la usan: [links]
           - Ventajas: [lista]
           - Desventajas: [lista]
           - Complejidad de implementaciÃ³n: 1-10
        
        2. **[Arquitectura 2]**: [DescripciÃ³n]
           [Misma estructura]
        
        ### Stack TecnolÃ³gico Recomendado
        - **Lenguajes**: [ej: Python, Rust] (basado en X papers)
        - **Frameworks**: [ej: PyTorch, JAX] (basado en Y papers)
        - **Infraestructura**: [ej: Docker, Kubernetes] (basado en Z papers)
        - **CI/CD**: [ej: GitHub Actions] (best practices de papers)
        
        ### Datasets para Prototipado
        - **[Dataset 1]**: [Por quÃ© este] | [Link]
        - **[Dataset 2]**: [Por quÃ© este] | [Link]
        
        ### MÃ©tricas de EvaluaciÃ³n
        - **[MÃ©trica 1]**: [DescripciÃ³n] | Usada en X papers
        - **[MÃ©trica 2]**: [DescripciÃ³n] | Usada en Y papers
        
        ## 10. Knowledge Base Construida
        - **Papers guardados en Supabase**: X papers
    - **Query para consultar**: `SELECT * FROM papers WHERE niche = '__NICHE__'`
        - **PDFs procesados disponibles**: Y archivos
        - **Secciones extraÃ­das**: Abstract, Introduction, Methods, Conclusion
        
        ## 11. Limitaciones y Consideraciones
        - âš ï¸ **Rate Limits hit**: [Si hubo problemas con Semantic Scholar]
        - âš ï¸ **PDFs no disponibles**: [Lista de papers sin PDF]
        - âš ï¸ **Papers paywalled**: [Papers detrÃ¡s de paywall]
        - ğŸ’¡ **Queries alternativas**: [Sugerencias si bÃºsqueda fue limitada]
        - ğŸš« **Red flags**: [Cualquier problema de calidad en papers]
        
        ## 12. PrÃ³ximos Pasos para TechnicalArchitect
        - **Enfocar diseÃ±o en**: [Subtemas/gaps especÃ­ficos]
        - **Priorizar metodologÃ­as**: [Top 2-3 metodologÃ­as]
    - **Explorar intersecciones**: [niche + tech X, niche + method Y]
    - **Validar con datasets**: [Datasets recomendados para pruebas]
    """.replace("__NICHE__", niche),
        
        agent=agent,
        
        # Recibe contexto del NicheAnalyst
        context=[niche_analysis_context] if niche_analysis_context else [],
    )
    
    logger.info(
        "literature_research_task_created",
        niche=niche,
        expected_duration="20-25 minutes",
        tools_used=["search_tool (5)", "pdf_tool (4)", "database_tool (3)"],
        bottleneck="semantic_scholar_rate_limit_1_req_per_sec",
    )
    
    return task


# FunciÃ³n helper
def create_literature_researcher(
    niche: str,
    niche_analysis_task: Optional[Task] = None
) -> tuple[Agent, Task]:
    """
    Helper para crear el LiteratureResearcher con su tarea.
    
    Args:
        niche: Nombre del niche a analizar
        niche_analysis_task: Task del NicheAnalyst (para recibir keywords)
    
    Returns:
        tuple[Agent, Task]: Tupla (agente, tarea)
    
    Example:
        >>> # DespuÃ©s de ejecutar NicheAnalyst
        >>> niche_agent, niche_task = create_niche_analyst("Rust + WebAssembly")
        >>> lit_agent, lit_task = create_literature_researcher(
        ...     "Rust + WebAssembly", 
        ...     niche_analysis_task=niche_task
        ... )
        >>> crew = Crew(
        ...     agents=[niche_agent, lit_agent],
        ...     tasks=[niche_task, lit_task],
        ...     process=Process.sequential
        ... )
        >>> result = crew.kickoff()
    """
    agent = create_literature_researcher_agent()
    task = create_literature_research_task(agent, niche, niche_analysis_task)
    return agent, task
