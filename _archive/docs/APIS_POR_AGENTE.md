# APIs Disponibles por Agente/Nodo

## üìã Resumen Ejecutivo

El ARA Framework actual soporta m√∫ltiples APIs para cada agente. Este documento detalla todas las opciones disponibles, incluyendo APIs remotas, locales y de terceros como GitHub Copilot, Cursor, Perplexity, etc.

---

## ü§ñ Agente 1: Niche Analyst (Analista de Nicho)

### **APIs Actuales (Implementadas)**
1. **GROQ** (LLM Principal)
   - Modelo: `mixtral-8x7b-32768` o `llama-3.1-8b-instant`
   - Uso: An√°lisis de mercado y tendencias
   - Costo: Gratis (l√≠mite: 14,400 req/d√≠a)
   - Latencia: ~1-2 segundos

2. **Semantic Scholar** (B√∫squeda de Papers)
   - Endpoint: `https://api.semanticscholar.org/graph/v1`
   - Uso: Buscar papers acad√©micos, tendencias de investigaci√≥n
   - Autenticaci√≥n: API Key (gratuita)
   - Rate limit: 1 req/seg

3. **Playwright** (Web Scraping)
   - Navegadores soportados: Chromium, Firefox, WebKit
   - Uso: Extraer informaci√≥n de GitHub, Reddit, HackerNews
   - Caracter√≠stica: Headless, stealth mode, anti-detection

### **APIs Alternativas Sugeridas**
| API | Tipo | Ventajas | Desventajas | Costo |
|-----|------|----------|-------------|--------|
| **OpenAI GPT-4** | LLM | Mejor calidad, m√°s grande | Rate limit bajo | $0.03/1K tokens |
| **Anthropic Claude** | LLM | Excelente para an√°lisis | API restrictiva | $0.003/1K tokens |
| **Azure OpenAI** | LLM (Empresa) | Mejor control, compliance | Setup complejo | Variable |
| **Llama 2 (Meta)** | LLM Local | Privacidad, sin l√≠mites | Requiere GPU local | Gratis |
| **Google Scholar API** | Search | Mejor cobertura acad√©mica | API cerrada (webscraping) | Gratis/Limitado |
| **arXiv API** | Search | Papers open-source | Menos papers industriales | Gratis |
| **Brave Search API** | Search | Mejor que Google | Costo moderado | $1-2/mes |

### **C√≥digo de Ejemplo - Alternativa GPT-4**
```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-4-turbo",
    temperature=0.1,
    api_key=os.getenv("OPENAI_API_KEY")
)
```

---

## üìö Agente 2: Literature Researcher (Investigador de Literatura)

### **APIs Actuales (Implementadas)**
1. **GROQ** (LLM Principal)
   - Uso: Sintetizar informaci√≥n de m√∫ltiples papers
   - Rol: Seleccionar y resumir literatura relevante

2. **Semantic Scholar** (B√∫squeda Avanzada)
   - Uso: Buscar papers por fecha, citaciones, autores
   - Caracter√≠stica: Acceso a metadatos completos

3. **Playwright** (PDF Extraction)
   - Uso: Descargar y procesar PDFs de papers
   - Limitaci√≥n: Algunos PDFs est√°n protegidos

### **APIs Alternativas Sugeridas**
| API | Tipo | Ventajas | Desventajas | Costo |
|-----|------|----------|-------------|--------|
| **CrossRef API** | Metadata | Informaci√≥n completa de papers | Requiere parsing | Gratis |
| **OpenAlex** | Academic Data | Mejor que Semantic Scholar | Menos papers recientes | Gratis |
| **Unpaywall** | PDF Access | Acceso a papers open-access | No todos los papers | Gratis |
| **PDF.js (local)** | PDF Processing | R√°pido, sin dependencias | Solo JavaScript | Gratis |
| **PyMuPDF (local)** | PDF Processing | Buena calidad, r√°pido | Dependencia nativa | Gratis |
| **PubMed API** | Medical Papers | Especializado en medicina | Scope limitado | Gratis |
| **IEEE Xplore API** | Technical Papers | Especializado en ingenier√≠a | Acceso limitado | Pago |

### **C√≥digo de Ejemplo - PDF Extraction Local**
```python
import fitz  # PyMuPDF

doc = fitz.open("paper.pdf")
text = ""
for page in doc:
    text += page.get_text()
```

---

## üèóÔ∏è Agente 3: Technical Architect (Arquitecto T√©cnico)

### **APIs Actuales (Implementadas)**
1. **GROQ** (LLM Principal)
   - Uso: Dise√±ar arquitectura t√©cnica
   - Rol: Crear diagramas y especificaciones

2. **Playwright** (Scraping de Documentaci√≥n)
   - Uso: Extraer documentaci√≥n t√©cnica
   - Fuentes: GitHub, Rust docs, WebAssembly specs

### **APIs Alternativas Sugeridas**
| API | Tipo | Ventajas | Desventajas | Costo |
|-----|------|----------|-------------|--------|
| **GitHub API** | Code Search | An√°lisis de repos, trending | Rate limit bajo (60 req/h) | Gratis |
| **GitLab API** | Code Search | Similar a GitHub | Alternativa | Gratis |
| **Stack Exchange API** | Q&A | Stack Overflow data | Limitado | Gratis |
| **DevDocs API** | Documentation | 500+ t√©cnicas documentadas | Read-only | Gratis |
| **AsyncIO (local)** | Parallelism | Ejecutar tareas en paralelo | Solo Python | Gratis |
| **Graphviz (local)** | Diagrams | Generar diagramas | Requiere instalaci√≥n | Gratis |

### **C√≥digo de Ejemplo - GitHub API**
```python
from github import Github

g = Github(os.getenv("GITHUB_TOKEN"))
repos = g.search_repositories(query="rust webassembly audio", sort="stars")

for repo in repos[:5]:
    print(f"{repo.name}: {repo.stargazers_count} stars")
```

---

## üíª Agente 4: Implementation Specialist (Especialista de Implementaci√≥n)

### **APIs Actuales (Implementadas)**
1. **GROQ** (LLM Principal)
   - Uso: Crear roadmap y user stories
   - Rol: Descomponer tareas complejas

2. **Playwright** (Scraping)
   - Uso: Buscar ejemplos de implementaci√≥n

### **APIs Alternativas Sugeridas**
| API | Tipo | Ventajas | Desventajas | Costo |
|-----|------|----------|-------------|--------|
| **Jira API** | Project Management | Crear issues autom√°ticamente | Requiere Jira Cloud | Pago |
| **GitHub Projects API** | Project Management | Integraci√≥n nativa | M√°s simple que Jira | Gratis |
| **Linear API** | Project Management | Moderno, r√°pido | Relativamente nuevo | Pago |
| **Notion API** | Documentation | Crear documentos | Lento | Gratis |
| **Markdown (local)** | Docs | R√°pido, versionable | No interactivo | Gratis |

### **C√≥digo de Ejemplo - GitHub Projects API**
```python
import requests

headers = {
    "Authorization": f"Bearer {GITHUB_TOKEN}",
    "Accept": "application/vnd.github.v3+json"
}

# Crear issue
issue_data = {
    "title": "Phase 1: Setup",
    "body": "Setup development environment",
    "labels": ["phase-1", "setup"]
}

r = requests.post(
    f"https://api.github.com/repos/{owner}/{repo}/issues",
    json=issue_data,
    headers=headers
)
```

---

## üìù Agente 5: Content Synthesizer (Sintetizador de Contenido)

### **APIs Actuales (Implementadas)**
1. **GROQ** (LLM Principal)
   - Uso: Generar reporte final
   - Rol: Integrar todo en un documento coherente

2. **Supabase** (Database)
   - Uso: Guardar an√°lisis completado
   - Caracter√≠stica: PostgreSQL con autenticaci√≥n

### **APIs Alternativas Sugeridas**
| API | Tipo | Ventajas | Desventajas | Costo |
|-----|------|----------|-------------|--------|
| **Markdown (local)** | Output | R√°pido, versionable | No interactivo | Gratis |
| **HTML Generator (local)** | Output | Mejor visualizaci√≥n | Requiere CSS | Gratis |
| **Pandoc (local)** | Conversion | Convertir a PDF, DOCX | Dependencia externa | Gratis |
| **WeasyPrint (local)** | PDF | Generar PDF desde HTML | Requiere instalaci√≥n | Gratis |
| **Google Docs API** | Cloud Storage | Colaboraci√≥n en tiempo real | Setup complejo | Gratis |
| **Notion API** | Cloud Storage | Crear p√°gina con contenido | Lento | Gratis |
| **Typeform API** | Forms | Obtener retroalimentaci√≥n | Scope limitado | Pago |

### **C√≥digo de Ejemplo - PDF Generation Local**
```python
from weasyprint import HTML, CSS

html_content = """
<html>
    <body>
        <h1>Research Report: Rust WebAssembly</h1>
        <p>Content here...</p>
    </body>
</html>
"""

HTML(string=html_content).write_pdf("report.pdf")
```

---

## üîå APIs de Terceros (GitHub Copilot, Cursor, Perplexity, etc.)

### 1. **GitHub Copilot** ‚≠ê
**Tipo:** LLM (Codex-based)
**Integraci√≥n:** IDE plugin (VS Code, JetBrains, etc.)
**Usos en ARA:**
- Generar boilerplate code para funciones
- Revisar c√≥digo de agentes
- Sugerir mejoras de arquitectura

**Limitaci√≥n:** No es una API HTTP, solo IDE plugin
**Alternativa:** Usar `copilot-cli` o GitHub Copilot API (beta)

```bash
# Instalar copilot CLI
npm install -g @github/copilot-cli

# Usar en terminal
copilot "<prompt>"
```

### 2. **Cursor Editor** üéØ
**Tipo:** IDE + LLM integrado
**Modelos soportados:** GPT-4, Claude
**Usos en ARA:**
- Escribir tests autom√°ticamente
- Refactorizar c√≥digo
- Generar documentaci√≥n

**Limitaci√≥n:** Es un editor, no una API
**Para ARA:** Podr√≠a usarse para desarrollo, no para ejecuci√≥n

### 3. **Perplexity API** üîç
**Tipo:** LLM + Search Engine
**Endpoint:** `https://api.perplexity.ai/chat/completions`
**Usos en ARA:**
- Buscar informaci√≥n actualizada
- Combinar LLM + Web Search

```python
import requests

headers = {
    "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
    "Content-Type": "application/json"
}

payload = {
    "model": "pplx-7b-online",  # Online model con web search
    "messages": [
        {
            "role": "user",
            "content": "What are the latest trends in Rust WebAssembly?"
        }
    ]
}

response = requests.post(
    "https://api.perplexity.ai/chat/completions",
    json=payload,
    headers=headers
)
```

**Costo:** $0.005/1K tokens (entrada), $0.02/1K tokens (salida)

### 4. **Ollama (Local LLM)** üè†
**Tipo:** Local LLM Server
**Modelos:** Llama 2, Mistral, Neural Chat, etc.
**Usos en ARA:**
- Privacidad total (datos locales)
- Sin rate limits
- Sin costos de API

```python
import requests

# Ollama escucha en localhost:11434
response = requests.post(
    "http://localhost:11434/api/generate",
    json={
        "model": "mistral",
        "prompt": "Analyze this niche: Rust WebAssembly",
        "stream": False
    }
)

print(response.json()['response'])
```

**Ventajas:** 
- Completamente privado
- Sin l√≠mites de rate
- Funcionamiento offline

**Desventajas:**
- Requiere GPU local
- Modelos menos potentes que GPT-4

### 5. **LM Studio (Local, GUI)** üñ•Ô∏è
**Tipo:** Local LLM con interfaz
**Similar a:** Ollama pero con GUI
**Modelos:** Llama 2, Mistral, etc.

### 6. **Claude API (Anthropic)** üß†
**Tipo:** LLM de alta calidad
**Endpoint:** `https://api.anthropic.com/v1/messages`
**Usos en ARA:**
- An√°lisis profundo de literatura
- S√≠ntesis de contenido complejo

```python
from anthropic import Anthropic

client = Anthropic()

message = client.messages.create(
    model="claude-3-opus-20240229",
    max_tokens=1024,
    messages=[
        {
            "role": "user",
            "content": "Analyze this niche..."
        }
    ]
)
```

**Ventajas:**
- Superior en an√°lisis de contexto
- Mejor para literatura acad√©mica
- Token limit muy alto (200K)

**Costo:** $0.015/1K tokens (entrada), $0.075/1K tokens (salida)

### 7. **LangSmith (Observabilidad)** üìä
**Tipo:** Monitoring y debugging para LangChain
**Usos en ARA:**
- Rastrear ejecuci√≥n de agentes
- Debugging de tool calls
- An√°lisis de costos

```python
import os
from langsmith import Client

# Set API key
os.environ["LANGCHAIN_API_KEY"] = "..."
os.environ["LANGCHAIN_PROJECT"] = "ara-framework"

# LangChain automaticamente registrar√° todas las llamadas
```

---

## üìä Matriz de Comparaci√≥n: APIs para LLM

| API | Costo | Velocidad | Calidad | Tool Call | Rate Limit | Mejor Para |
|-----|-------|-----------|---------|-----------|-----------|-----------|
| **GROQ (Mixtral)** | üü¢ Gratis | ‚ö° R√°pido | üü° Bueno | ‚úÖ Excelente | 14.4K/d√≠a | Prototipo r√°pido |
| **OpenAI GPT-4** | üî¥ $$$$ | üü° Medio | üü¢ Excelente | ‚úÖ Perfecto | 40K/min | Producci√≥n |
| **Claude 3** | üü° $$ | üü° Medio | üü¢ Excelente | ‚úÖ Bueno | 50K/min | Literatura, an√°lisis |
| **Perplexity** | üü° $ | ‚ö° R√°pido | üü° Bueno | ‚ö†Ô∏è Limitado | 100/min | Web search integrado |
| **Llama Local** | üü¢ Gratis | üü° Variable | üü° Bueno | ‚ö†Ô∏è Limitado | ‚ôæÔ∏è Ilimitado | Privacidad total |
| **Ollama** | üü¢ Gratis | üü° Variable | üü° Bueno | ‚ö†Ô∏è Limitado | ‚ôæÔ∏è Ilimitado | Testing local |

---

## üîß Implementaci√≥n Recomendada por Escenario

### **Escenario 1: Desarrollo Local (Tu PC)**
```python
# .env
LLM_PROVIDER=ollama
OLLAMA_MODEL=mistral
SEMANTIC_SCHOLAR_API_KEY=...
# Sin costos, datos privados
```

### **Escenario 2: Producci√≥n (M√°xima Calidad)**
```python
# .env
LLM_PROVIDER=openai
OPENAI_MODEL=gpt-4-turbo
SEARCH_PROVIDER=perplexity  # Para datos recientes
# Costo: $20-100/mes
```

### **Escenario 3: An√°lisis Acad√©mico Especializado**
```python
# .env
LLM_PROVIDER=anthropic
ANTHROPIC_MODEL=claude-3-opus
SEARCH_PROVIDER=semantic_scholar
PDF_PROCESSOR=pymupdf  # Local
# Costo: $10-30/mes
```

### **Escenario 4: M√°xima Velocidad (Startup)**
```python
# .env
LLM_PROVIDER=groq
GROQ_MODEL=mixtral-8x7b-32768
SEARCH_PROVIDER=semantic_scholar
# Costo: Gratis (con l√≠mites)
```

---

## üöÄ Pr√≥ximos Pasos Recomendados

1. **Integrar m√∫ltiples LLMs** - Permitir switching entre GROQ, OpenAI, Claude
2. **Agregar Perplexity** - Para b√∫squeda web en tiempo real
3. **Soportar Ollama local** - Opci√≥n privada para desarrollo
4. **LangSmith integration** - Monitoreo de la pipeline
5. **Fallback strategy** - Si GROQ falla, usar OpenAI

---

## üìù Notas

- **API Keys:** Nunca pushear a GitHub, usar `.env`
- **Rate Limits:** Implementar retry logic con exponential backoff
- **Caching:** Redis para resultados recientes (ya implementado)
- **Monitoring:** LangSmith para debugging
- **Cost Control:** Establecer budget limits en APIs de pago

