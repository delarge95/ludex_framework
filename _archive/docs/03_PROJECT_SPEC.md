# ðŸ“‹ EspecificaciÃ³n del Proyecto: Marco ARA (Agente de InvestigaciÃ³n AutÃ³nomo)

## ðŸŽ¯ VisiÃ³n del Proyecto

### Â¿QuÃ© estamos construyendo?

Un **sistema multi-agente autÃ³nomo** capaz de generar tesis acadÃ©micas completas de forma automatizada, utilizando IA avanzada para replicar el proceso de investigaciÃ³n humano pero a escala y velocidad sin precedentes.

### Â¿Por quÃ© es importante?

#### Problema Actual:

1. **Barrera de Entrada Alta**: Escribir una tesis de calidad requiere meses de investigaciÃ³n manual
2. **Trabajo Repetitivo**: Mucha de la investigaciÃ³n implica tareas mecÃ¡nicas (bÃºsqueda de papers, extracciÃ³n de datos, formateo)
3. **Inconsistencia**: La calidad depende enormemente del investigador individual
4. **No Escalable**: Un investigador humano solo puede trabajar en 1-2 tesis simultÃ¡neamente

#### Nuestra SoluciÃ³n:

Un equipo de **agentes de IA especializados** que:

- Automatizan la bÃºsqueda y anÃ¡lisis de literatura
- Realizan anÃ¡lisis de mercado en tiempo real
- Generan especificaciones tÃ©cnicas detalladas
- Sintetizan contenido acadÃ©mico coherente y bien fundamentado

#### Impacto:

- âœ… Reducir tiempo de generaciÃ³n de tesis de **meses a horas**
- âœ… Democratizar el acceso a investigaciÃ³n de calidad
- âœ… Permitir investigaciÃ³n paralela en mÃºltiples dominios
- âœ… Establecer un nuevo paradigma en investigaciÃ³n asistida por IA

---

## ðŸ—ï¸ Arquitectura Conceptual

### Paradigma: Flujos de Trabajo AgÃ©nticos vs. AutomatizaciÃ³n Tradicional

El Marco ARA NO es:

- âŒ Un simple script de automatizaciÃ³n lineal
- âŒ Un chatbot con un solo LLM monolÃ­tico
- âŒ Una herramienta de "generaciÃ³n de texto con prompts"

El Marco ARA ES:

- âœ… Un **sistema multi-agente** donde cada agente tiene roles y herramientas especializadas
- âœ… Un **workflow dinÃ¡mico** que se adapta al contexto
- âœ… Una **arquitectura de microservicios** para herramientas desacopladas
- âœ… Un **pipeline secuencial** con validaciÃ³n en cada etapa

### FilosofÃ­a de DiseÃ±o: "DivisiÃ³n del Trabajo"

Inspirado en equipos de investigaciÃ³n reales:

- El **Analista de Mercado** identifica problemas viables
- El **Investigador AcadÃ©mico** revisa literatura y teorÃ­as
- El **Arquitecto TÃ©cnico** diseÃ±a soluciones
- El **Escritor** sintetiza todo en un documento coherente

Cada agente es **autÃ³nomo pero colaborativo**, con su propio conjunto de herramientas especializadas.

---

## ðŸ‘¥ El Elenco de Agentes

### 1. **ProjectManager** ðŸŽ©

**Responsabilidad**: OrquestaciÃ³n y control de calidad

**Tareas**:

- Asignar tareas a agentes especializados
- Monitorear progreso del pipeline
- Validar que cada secciÃ³n cumple requisitos estructurales
- Resolver conflictos entre agentes

**Herramientas**:

- Task Assignment Tool
- Quality Validation Tool
- Inter-Agent Communication Protocol

**Salida**: Plan de ejecuciÃ³n y reporte de validaciÃ³n

---

### 2. **NicheAnalyst** ðŸ”

**Responsabilidad**: Identificar problemas viables y oportunidades de mercado

**Tareas**:

- Analizar tendencias de mercado en un dominio especÃ­fico
- Escanear actividad de la competencia
- Recolectar sentimiento del consumidor
- Identificar "espacios en blanco" (whitespace opportunities)

**Herramientas**:

- WebScraping MCP Server (Playwright-based)
  - `search_and_extract()`: Buscar productos en e-commerce
  - `extract_product_details()`: Extraer informaciÃ³n de pÃ¡ginas de producto
  - `extract_reviews()`: Recolectar reseÃ±as de clientes
  - `scan_competitor_websites()`: Analizar features de competidores

**Salida**: Secciones "Planteamiento del Problema" y "JustificaciÃ³n"

**Ejemplo de EjecuciÃ³n**:

```
Input: "Analizar mercado de bebidas espirituosas premium"
â†“
Agente planea:
1. Escanear sitios web de Absolut, Grey Goose, Belvedere
2. Buscar reseÃ±as en Drizly, ReserveBar
3. Identificar tecnologÃ­as de marketing utilizadas

â†“
Ejecuta herramientas:
- scan_features("https://www.greygoose.com") â†’ {"has_web3d": false}
- extract_reviews("drizly", "Absolut Vodka") â†’ {"sentiment": "neutral", "common_complaint": "lack_of_engaging_experience"}

â†“
Sintetiza hallazgos:
"Los competidores no utilizan experiencias Web 3D inmersivas.
Los consumidores buscan experiencias de compra mÃ¡s atractivas para productos premium."
```

---

### 3. **LiteratureResearcher** ðŸ“š

**Responsabilidad**: ConstrucciÃ³n del Estado del Arte y Marco TeÃ³rico

**Tareas**:

- BÃºsqueda por palabras clave en bases de datos acadÃ©micas
- Descarga y procesamiento de PDFs acadÃ©micos
- Resumen individual de papers
- AnÃ¡lisis temÃ¡tico y extracciÃ³n de marcos teÃ³ricos
- IdentificaciÃ³n de brechas de investigaciÃ³n (gap analysis)

**Herramientas**:

- **Academic Search Tools**:
  - `search_semantic_scholar(query, year_filter)`: BÃºsqueda en Semantic Scholar
  - `search_arxiv(query)`: BÃºsqueda en ArXiv
- **PDF Ingestion MCP Server**:
  - `process_pdf(url)`: Extrae contenido estructurado de PDFs acadÃ©micos

**Salida**: Secciones "Estado del Arte", "Marco TeÃ³rico" y "Gap Analysis"

**Pipeline de EjecuciÃ³n**:

```
1. BÃºsqueda de Papers:
   Keywords: ["Web 3D", "Immersive Storytelling", "PBR Rendering"]
   â†’ Retrieval: 50 papers relevantes

2. Filtrado:
   Criterios: Year > 2018, Citations > 10
   â†’ Filtered: 15 papers de alta calidad

3. Procesamiento:
   Para cada paper:
     - Descargar PDF
     - Extraer texto estructurado (Unstructured.io)
     - Generar resumen con LLM

4. SÃ­ntesis TemÃ¡tica:
   Agrupar papers por:
   - Marcos teÃ³ricos (e.g., "Modelo S-O-R")
   - MetodologÃ­as (e.g., "Desarrollo Ãgil")
   - Limitaciones mencionadas

5. Gap Analysis:
   Identificar preguntas no respondidas en la literatura
```

---

### 4. **TechnicalArchitect** âš™ï¸

**Responsabilidad**: DiseÃ±o de soluciones tÃ©cnicas y especificaciones

**Tareas**:

- SelecciÃ³n de stack tecnolÃ³gico justificado
- DiseÃ±o de arquitectura de software
- DefiniciÃ³n de componentes y APIs
- IdentificaciÃ³n de desafÃ­os de implementaciÃ³n
- CoordinaciÃ³n de generaciÃ³n de activos 3D

**Herramientas**:

- Code Repository Search Tools
- Blender Control MCP Server (para generaciÃ³n de activos)
- Generative 3D Tools (TripoSR)

**Salida**: SecciÃ³n "Especificaciones TÃ©cnicas del MVP"

---

### 5. **ImplementationSpecialist** ðŸ’»

**Responsabilidad**: EjecuciÃ³n de tareas tÃ©cnicas programÃ¡ticas

**Tareas**:

- GeneraciÃ³n de activos 3D desde imÃ¡genes
- Refinamiento de modelos en Blender
- AplicaciÃ³n de materiales PBR
- Renderizado de imÃ¡genes de prueba
- EjecuciÃ³n de scripts de construcciÃ³n

**Herramientas**:

- FileSystem MCP Server
- Code Execution Tool
- Blender Control MCP Server (ejecuciÃ³n de comandos)

**Salida**: Activos visuales y cÃ³digo boilerplate

---

### 6. **ContentSynthesizer** âœï¸

**Responsabilidad**: Ensamblaje final del documento de tesis

**Tareas**:

- UnificaciÃ³n de tono y estilo
- Formateo segÃºn plantilla acadÃ©mica
- GeneraciÃ³n de transiciones entre secciones
- GestiÃ³n de citas bibliogrÃ¡ficas
- IntegraciÃ³n de elementos visuales (figuras, tablas)

**Herramientas**:

- Text Formatting Tools
- Citation Management Tools
- Document Assembly Pipeline

**Salida**: Documento de tesis completo y formateado (PDF/LaTeX/DOCX)

---

## ðŸ”§ El PatrÃ³n "Servidor MCP": Herramientas como Microservicios

### Problema:

Los agentes necesitan capacidades mÃ¡s allÃ¡ de la generaciÃ³n de lenguaje:

- Navegar la web con JavaScript complejo
- Procesar PDFs con layouts multi-columna
- Controlar software externo (Blender)
- Ejecutar cÃ³digo computacionalmente intensivo

### SoluciÃ³n ArquitectÃ³nica:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LangGraph Agents Layer                    â”‚
â”‚  [NicheAnalyst] [LiteratureResearcher] [TechnicalArchitect] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚               â”‚                â”‚
             â”‚  HTTP REST    â”‚  HTTP REST     â”‚  HTTP REST
             â–¼               â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  WebScraping     â”‚  â”‚ PDF Ingestionâ”‚  â”‚ Blender Control â”‚
â”‚  MCP Server      â”‚  â”‚ MCP Server   â”‚  â”‚ MCP Server      â”‚
â”‚                  â”‚  â”‚              â”‚  â”‚                 â”‚
â”‚  FastAPI         â”‚  â”‚  FastAPI     â”‚  â”‚  FastAPI + ZMQ  â”‚
â”‚  + Playwright    â”‚  â”‚  + Unstruct. â”‚  â”‚  + Blender API  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Beneficios:

1. **Desacoplamiento**: Los agentes no conocen la implementaciÃ³n de las herramientas
2. **Modularidad**: Cada servidor es independiente, fÃ¡cil de desarrollar y probar
3. **Escalabilidad**: Cada servidor puede correr en su propio contenedor
4. **GestiÃ³n de Dependencias**: Bibliotecas pesadas (PyTorch, Playwright) aisladas

### Ejemplo de ImplementaciÃ³n:

**Servidor (FastAPI)**:

```python
from fastapi import FastAPI
from playwright.async_api import async_playwright

app = FastAPI()

@app.post("/scrape/product_details")
async def scrape_product_details(url: str) -> dict:
    async with async_playwright() as p:
        browser = await p.chromium.launch()
        page = await browser.new_page()
        await page.goto(url)

        title = await page.locator("h1.product-title").text_content()
        price = await page.locator(".price").text_content()

        await browser.close()

        return {"title": title, "price": price}
```

**Cliente (Agent Tool)**:

```python
import requests

def scrape_product_details(url: str) -> dict:
    """Herramienta que los agentes pueden usar."""
    response = requests.post(
        "http://localhost:8001/scrape/product_details",
        json={"url": url}
    )
    return response.json()
```

---

## ðŸ”„ Pipeline de EjecuciÃ³n Secuencial

### Flujo Completo:

```
[USER INPUT]
    "Generar tesis sobre: Marketing digital para bebidas premium"
    â†“
[PHASE 0: Initialization]
    ProjectManager crea plan de ejecuciÃ³n
    â†’ Asigna tareas a agentes
    â†“
[PHASE 1: Problem Discovery] (~5 min)
    NicheAnalyst ejecuta:
    1. Escanea sitios de competidores
    2. Analiza reseÃ±as de consumidores
    3. Identifica brecha de mercado
    â†’ OUTPUT: "Planteamiento del Problema" + "JustificaciÃ³n"
    â†“
[PHASE 2: Literature Review] (~15 min)
    LiteratureResearcher ejecuta:
    1. Busca 50 papers en Semantic Scholar + ArXiv
    2. Procesa PDFs con Unstructured.io
    3. Resume cada paper individualmente
    4. Realiza anÃ¡lisis temÃ¡tico
    5. Identifica gaps de investigaciÃ³n
    â†’ OUTPUT: "Estado del Arte" + "Marco TeÃ³rico" + "Gap Analysis"
    â†“
[PHASE 3: Technical Design] (~8 min)
    TechnicalArchitect ejecuta:
    1. Analiza requisitos del problema
    2. Selecciona stack tecnolÃ³gico (React Three Fiber, GSAP, etc.)
    3. DiseÃ±a arquitectura de componentes
    4. Genera diagramas tÃ©cnicos
    â†’ OUTPUT: "Especificaciones TÃ©cnicas del MVP"
    â†“
[PHASE 4: Asset Generation] (~5 min)
    ImplementationSpecialist ejecuta:
    1. Genera modelo 3D base con TripoSR
    2. Refina en Blender (vÃ­a MCP Server)
    3. Aplica materiales PBR
    4. Renderiza imÃ¡genes de prueba
    â†’ OUTPUT: Activos visuales (renders, diagramas)
    â†“
[PHASE 5: Synthesis] (~7 min)
    ContentSynthesizer ejecuta:
    1. Recibe todas las secciones generadas
    2. Unifica tono y estilo
    3. Genera transiciones
    4. Formatea citas bibliogrÃ¡ficas
    5. Inserta figuras y tablas
    6. Genera documento final
    â†’ OUTPUT: Documento de tesis completo (PDF)
    â†“
[PROJECT MANAGER: Quality Check]
    Valida estructura, coherencia y completitud
    â†’ Si pasa: Entrega final
    â†’ Si falla: Re-asigna tareas de correcciÃ³n
```

**Tiempo Total Estimado**: 30-40 minutos para una tesis completa

---

## ðŸŽ¯ Criterios de Ã‰xito

### MÃ©tricas Cuantitativas:

- [ ] GeneraciÃ³n de tesis completa en **< 45 minutos**
- [ ] Coherencia temÃ¡tica (validaciÃ³n por evaluador humano): **> 8/10**
- [ ] PrecisiÃ³n fÃ¡ctica (citas reales y verificables): **> 95%**
- [ ] Estructura completa (todas las secciones requeridas): **100%**

### MÃ©tricas Cualitativas:

- [ ] El documento debe ser **indistinguible de una tesis escrita por humano** (Turing test)
- [ ] Las recomendaciones tÃ©cnicas deben ser **implementables y actuales**
- [ ] Las citas acadÃ©micas deben ser **relevantes y correctamente contextualizadas**
- [ ] El anÃ¡lisis de mercado debe estar **fundamentado en datos reales**

---

## ðŸš€ Caso de Uso de Ejemplo

**Input del Usuario**:

```
Dominio: "Marketing de Bebidas Espirituosas Premium"
Marca Foco: "Absolut Vodka"
TecnologÃ­a Propuesta: "Experiencias Web 3D Interactivas"
```

**Output Esperado**:
Un documento de tesis de ~60 pÃ¡ginas que incluye:

1. **IntroducciÃ³n y Planteamiento del Problema** (5 pags)

   - AnÃ¡lisis de la brecha de storytelling digital en el sector
   - JustificaciÃ³n basada en datos de mercado reales

2. **Estado del Arte y Marco TeÃ³rico** (15 pags)

   - RevisiÃ³n de 15+ papers sobre Web 3D, storytelling inmersivo
   - Marcos teÃ³ricos: Modelo S-O-R, TeorÃ­a de Presencia Mediada
   - Gap analysis: Falta de plataformas 3D centralizadas

3. **Especificaciones TÃ©cnicas del MVP** (10 pags)

   - Stack: React Three Fiber, Three.js, GSAP, Vite
   - Arquitectura de componentes
   - Materiales PBR para renderizado fotorrealista

4. **Desarrollo e ImplementaciÃ³n** (20 pags)

   - Pipeline de activos 3D
   - CÃ³digo de ejemplo para componentes clave
   - Renders de alta calidad del producto

5. **Resultados y Conclusiones** (10 pags)
   - ValidaciÃ³n tÃ©cnica del MVP
   - AnÃ¡lisis de impacto potencial
   - Futuras lÃ­neas de investigaciÃ³n

**Valor Agregado**:

- âœ… Todo fundamentado en datos reales (no alucinaciones)
- âœ… Citas acadÃ©micas verificables
- âœ… Especificaciones tÃ©cnicas implementables
- âœ… Activos visuales de alta calidad

---

## ðŸŒ Impacto y Futuro

### Impacto Inmediato:

- Acelerar generaciÃ³n de tesis de grado/maestrÃ­a
- Democratizar acceso a investigaciÃ³n de calidad
- Establecer nuevo estÃ¡ndar en investigaciÃ³n asistida por IA

### EvoluciÃ³n Futura:

1. **Ajuste Fino de Modelos**: Entrenar LLMs especializados en dominios especÃ­ficos
2. **Agentes Colaborativos**: MÃºltiples agentes debatiendo hipÃ³tesis
3. **ValidaciÃ³n AutomÃ¡tica**: VerificaciÃ³n de claims contra bases de datos
4. **Multi-Modalidad**: GeneraciÃ³n de videos, presentaciones, demos interactivos

### Limitaciones Conocidas:

- âš ï¸ Requiere supervisiÃ³n humana para validaciÃ³n final
- âš ï¸ Dependiente de calidad de datos accesibles (APIs, papers abiertos)
- âš ï¸ No reemplaza el juicio crÃ­tico humano, lo aumenta

---

## ðŸ“Š ACTUALIZACIÃ“N NOVIEMBRE 2025: Requerimientos Validados

> **Fuente**: InvestigaciÃ³n exhaustiva Nov 2025 (MiniMax + Perplexity + Gemini)  
> **Estado**: âœ… ESPECIFICACIONES ACTUALIZADAS CON DATOS REALES

### 1. **SLAs de Performance Revisados (Basados en Evidencia)**

#### **Pipeline Completo: Tiempos Reales**

```yaml
performance_slas:
  original_target: "< 45 minutos"
  status: "âŒ NO VIABLE (basado en investigaciÃ³n tÃ©cnica)"

  realistic_targets:
    optimistic: "60-75 minutos"
    confidence: "85%"
    assumptions:
      - "ParalelizaciÃ³n implementada"
      - "Caching funcionando"
      - "Rate limits manejados"

    realistic: "135-165 minutos"
    confidence: "95%"
    assumptions:
      - "Flujo secuencial sin optimizaciones"
      - "APIs externas con delays"
      - "Procesamiento PDFs variable"

  recommended_target: "60-75 minutos"
  justification: |
    Alcanzable con optimizaciones incrementales.
    AÃºn representa 99% de ahorro vs investigaciÃ³n manual (6-18 meses).
```

#### **SLAs por Agente (Validados con InvestigaciÃ³n)**

```yaml
agent_slas:
  NicheAnalyst:
    original: "~5 minutos"
    validated: "7-8 minutos"
    deviation: "+60%"
    bottlenecks:
      - "Scraping de sitios JS-heavy con anti-bot"
      - "Rate limits de proveedores (Google, Bing)"
      - "Variabilidad en tiempos de respuesta de pÃ¡ginas"
    mitigation:
      - "Playwright con stealth mode"
      - "Proxies rotativos (solo si necesario)"
      - "Caching de bÃºsquedas repetitivas (TTL 24h)"

  LiteratureResearcher:
    original: "~15 minutos"
    validated: "20-25 minutos"
    deviation: "+67%"
    bottlenecks:
      - "âš ï¸ CRÃTICO: Semantic Scholar 1 RPS (solicitud por segundo)"
      - "Descarga de 15-50 papers en cola secuencial"
      - "Parsing de PDFs con layouts complejos"
    mitigation:
      - "Cola de trabajo paralela con RateLimitedQueue"
      - "Prefetch de papers mÃ¡s citados"
      - "PyMuPDF para velocidad (0.12s/pÃ¡gina vs 1.29s Unstructured)"
    code_example: |
      async def fetch_papers_parallel(queries, rate_limit=1):
          queue = RateLimitedQueue(rate_limit=rate_limit)
          tasks = [queue.enqueue(fetch_paper, q) for q in queries]
          return await asyncio.gather(*tasks)

  TechnicalArchitect:
    original: "~8 minutos"
    validated: "10-12 minutos"
    deviation: "+50%"
    bottlenecks:
      - "Latencia de modelos premium (Claude Sonnet 4.5: 2-3s)"
      - "GeneraciÃ³n de diagramas complejos"
      - "ValidaciÃ³n de especificaciones tÃ©cnicas"
    mitigation:
      - "Usar Claude Sonnet 4.5 (77.2% SWE-bench)"
      - "Templates de arquitectura pre-cargados"
      - "GeneraciÃ³n paralela de diagramas"

  ImplementationSpecialist:
    original: "~5 minutos"
    validated: "7-8 minutos"
    deviation: "+60%"
    bottlenecks:
      - "Rendering 3D con Blender (headless)"
      - "GeneraciÃ³n de assets mÃºltiples"
      - "Control de calidad de renders"
    mitigation:
      - "Blender + pyzmq en modo batch"
      - "TripoSR para generaciÃ³n rÃ¡pida (GPU: RTX 3060+)"
      - "Cloud GPU para cargas intensivas"

  ContentSynthesizer:
    original: "~7 minutos"
    validated: "9-10 minutos"
    deviation: "+43%"
    bottlenecks:
      - "GestiÃ³n de 50-100 citas bibliogrÃ¡ficas"
      - "ValidaciÃ³n de consistencia entre secciones"
      - "Formateo de documento extenso (50-80 pÃ¡ginas)"
    mitigation:
      - "Templates de LaTeX pre-validados"
      - "BibTeX automation con validaciÃ³n"
      - "Gates de calidad automatizados"

  Orchestration_Overhead:
    original: "2-5 minutos"
    validated: "5-7 minutos"
    deviation: "+100%"
    bottlenecks:
      - "Traspaso de contexto entre agentes (100-500ms cada uno)"
      - "Estudios Anthropic: hasta 15x mÃ¡s tokens en multi-agente"
      - "ValidaciÃ³n entre fases (gates de calidad)"
    mitigation:
      - "âœ… Arquitectura basada en artefactos (NO conversacional)"
      - "Agentes consumen/producen JSON/Markdown"
      - "Elimina 80% de overhead de tokens"
```

### 2. **AsignaciÃ³n de Modelos por Agente (Oficial)**

```yaml
model_assignments:
  budget:
    monthly: "$10-18"
    copilot_credits: 300
    projected_usage: 45 # 15% del total
    buffer: 255 # 85% para spikes

  agents:
    NicheAnalyst:
      model: "gpt-4o"
      provider: "GitHub Copilot Pro"
      cost: "0x crÃ©ditos (GRATIS)"
      benchmarks:
        humaneval: "88%"
        mmlu: "88.7%"
      justification: "Suficiente para anÃ¡lisis de mercado, multimodal, sin costo"
      fallback: "minimax-m2 (69.4% SWE-bench, $0)"

    LiteratureResearcher:
      model: "gemini-2.5-pro"
      provider: "Google AI Studio"
      cost: "$0 (plan gratuito)"
      benchmarks:
        context: "1M tokens â­"
        humaneval: "90%"
      justification: "CRÃTICO: 1M contexto para analizar 10-50 papers simultÃ¡neamente"
      usage_pattern: "10-50 papers Ã— 5-10K tokens/paper = 50-500K tokens â†’ requiere 1M contexto"
      fallback: "deepseek-v3 (92% HumanEval, 128K ctx, $0)"

    TechnicalArchitect:
      model: "claude-sonnet-4.5"
      provider: "GitHub Copilot Pro"
      cost: "1x crÃ©dito"
      benchmarks:
        swe_bench: "77.2% (SOTA) â­"
        mmlu: "88%"
      justification: "Mejor para diseÃ±o arquitectÃ³nico SWE-level, razonamiento profundo"
      estimated_usage: "10 anÃ¡lisis/mes Ã— 1 crÃ©dito = 10 crÃ©ditos"
      fallback: "gpt-5 (72.8% SWE-bench, 1x crÃ©dito)"

    FinancialAnalyst:
      model: "gpt-5"
      provider: "GitHub Copilot Pro"
      cost: "1x crÃ©dito"
      benchmarks:
        mmlu: "88.7%"
        gsm8k: "~92%"
      justification: "MÃ¡xima precisiÃ³n matemÃ¡tica y razonamiento complejo"
      estimated_usage: "15 anÃ¡lisis/mes Ã— 1 crÃ©dito = 15 crÃ©ditos"
      fallback: "claude-sonnet-4.5 (88% MMLU, 1x crÃ©dito)"

    StrategyProposer:
      model: "claude-haiku-4.5"
      provider: "GitHub Copilot Pro"
      cost: "0.33x crÃ©ditos"
      benchmarks:
        ifbench: "72% (seguimiento instrucciones) â­"
        latency: "600-1000ms (4-5x mÃ¡s rÃ¡pido)"
        swe_bench: "73.3%"
      justification: "Mejor para propuestas estratÃ©gicas, baja latencia, ROI Ã³ptimo"
      estimated_usage: "20 anÃ¡lisis/mes Ã— 0.33 crÃ©dito = 6.6 crÃ©ditos"
      fallback: "gpt-4o (0x crÃ©ditos, equivalente en escritura)"

    ReportGenerator:
      model: "minimax-m2"
      provider: "MiniMax API / Self-hosted"
      cost: "$0"
      benchmarks:
        swe_bench: "69.4%"
        params: "229B MoE (10B activos)"
        license: "MIT (open-source)"
      justification: "GeneraciÃ³n de cÃ³digo alta calidad, sin costo, self-hosted viable"
      estimated_usage: "20 anÃ¡lisis/mes Ã— $0 = $0"
      fallback: "gpt-4o (88% HumanEval, 0x crÃ©ditos)"

    OrchestratorAgent:
      model: "claude-haiku-4.5"
      provider: "GitHub Copilot Pro"
      cost: "0.33x crÃ©ditos"
      benchmarks:
        latency: "600-1000ms â­"
        computer_use: "50.7% OSWorld"
      justification: "Decisiones rÃ¡pidas en orquestaciÃ³n, baja latencia crÃ­tica"
      estimated_usage: "10 anÃ¡lisis/mes Ã— 0.33 crÃ©dito = 3.3 crÃ©ditos"
      fallback: "gpt-4o (0x crÃ©ditos, 1.2-1.6s latency)"

  total_budget:
    copilot_credits_used: 45 # de 300 disponibles
    percentage_used: "15%"
    buffer_remaining: "85%"
    monthly_cost: "$10 (suscripciÃ³n Copilot Pro)"
    apis_external: "$0-8 (uso moderado APIs gratuitas)"
    total: "$10-18/mes"
```

### 3. **Servidores MCP: EspecificaciÃ³n TÃ©cnica Completa**

```yaml
mcp_servers:
  total_count: 8
  total_cost: "$0/mes (100% gratuito)"

  servers:
    - name: "GitHub MCP"
      status: "âœ… REQUIRED"
      provider: "GitHub (oficial)"
      capabilities:
        - "Repositorios (read/write)"
        - "Issues, PRs, discussions"
        - "Security alerts, Actions"
      rate_limits: "SegÃºn polÃ­ticas API GitHub"
      authentication: "PAT con scopes mÃ­nimos (repo, read:org)"
      sla: "< 2s por request"

    - name: "Playwright MCP"
      status: "âœ… REQUIRED"
      provider: "ExecuteAutomation (comunidad)"
      capabilities:
        - "Web scraping moderno (SPAs)"
        - "Auto-waiting inteligente"
        - "Multi-browser (Chromium, Firefox, WebKit)"
      performance: "Superior a Selenium en SPAs"
      sla: "< 5s por pÃ¡gina"
      mitigation: "Proxies rotativos solo si sitio lo requiere"

    - name: "MarkItDown MCP"
      status: "âœ… REQUIRED"
      provider: "Microsoft"
      capabilities:
        - "PDF â†’ Markdown"
        - "DOCX, PPTX â†’ Markdown"
      performance:
        pymupdf: "~0.12s/pÃ¡gina (rÃ¡pido)"
        unstructured: "~1.29s/pÃ¡gina (semÃ¡ntico)"
      strategy: "PyMuPDF para velocidad, Unstructured para RAG"
      sla: "< 10s por PDF de 20 pÃ¡ginas"

    - name: "Jina AI Reader MCP"
      status: "âœ… REQUIRED (reemplazo Firecrawl)"
      provider: "Jina AI"
      capabilities:
        - "URL â†’ Markdown limpio"
        - "Scraping estructurado"
      rate_limits:
        without_key: "20 RPM"
        with_free_key: "200 RPM"
        tokens: "10M tokens incluidos"
      cost: "$0"
      usage_estimate: "100 anÃ¡lisis Ã— 2 requests = 200 req/mes (dentro de lÃ­mite)"
      sla: "< 3s por URL"

    - name: "Supabase MCP"
      status: "âœ… REQUIRED"
      provider: "Supabase"
      free_tier_limits:
        database: "500 MB"
        storage: "1 GB"
        egress: "5 GB/mes"
        mau: "50,000 usuarios"
        realtime: "2M mensajes/mes"
      warnings:
        - "Proyectos se pausan tras 1 semana inactividad"
        - "Monitorear uso para evitar pausa"
      usage_pattern: "Metadatos de anÃ¡lisis + cache de resultados"
      sla: "< 100ms queries"

    - name: "Notion MCP"
      status: "âœ… OPTIONAL"
      provider: "Notion API"
      capabilities:
        - "GestiÃ³n de conocimiento"
        - "DocumentaciÃ³n interna"
        - "Tracking de investigaciÃ³n"
      rate_limits:
        average: "3 req/s"
        burst: "Parcialmente permitido"
        payload: "1000 bloques, 500 KB"
      error_handling: "HTTP 429 â†’ respetar Retry-After"
      sla: "< 2s por operaciÃ³n"

    - name: "ChromeDevTools MCP"
      status: "âœ… OPTIONAL (debugging)"
      capabilities:
        - "Network monitoring"
        - "Console logs"
        - "Debugging scraping"
      use_case: "Desarrollo y troubleshooting"

    - name: "Rube MCP"
      status: "âš ï¸ TBD (evaluar)"
      capabilities:
        - "OrquestaciÃ³n workflows"
        - "Multi-tool execution"
      status_note: "Integrated with LangGraph StateGraph"

  rejected_servers:
    - name: "Firecrawl MCP"
      cost: "$49/mes mÃ­nimo"
      reason: "âŒ Rompe restricciÃ³n presupuestaria $0"
      replacement: "Jina AI Reader (200 RPM gratis)"
```

### 4. **Presupuesto y Capacidad Operativa**

```yaml
operational_capacity:
  monthly_budget:
    copilot_pro: "$10"
    apis_external: "$0-8"
    total: "$10-18"
    confidence: "95%"

  analyses_per_month:
    target: 100
    cost_per_analysis: "$0.10-0.18"
    roi_vs_manual:
      manual_cost: "$25/anÃ¡lisis (30 min Ã— $50/hora)"
      automated_cost: "$0.15/anÃ¡lisis"
      savings: "$24.85/anÃ¡lisis (99.4%)"
      monthly_savings: "$2,485 (100 anÃ¡lisis)"
      roi_multiplier: "166x"

  credit_management:
    copilot_credits:
      allocated: 300
      projected_usage: 45
      buffer: 255
      alert_threshold: 240 # Alertar si < 60 crÃ©ditos

    usage_by_agent:
      FinancialAnalyst: "15 crÃ©ditos (15 Ã— 1.0)"
      TechnicalArchitect: "10 crÃ©ditos (10 Ã— 1.0)"
      StrategyProposer: "6.6 crÃ©ditos (20 Ã— 0.33)"
      OrchestratorAgent: "3.3 crÃ©ditos (10 Ã— 0.33)"
      Others: "10 crÃ©ditos (buffer spikes)"
      total: "44.9 crÃ©ditos"

  scalability:
    current_capacity: "100 anÃ¡lisis/mes"
    bottleneck: "Semantic Scholar 1 RPS (rate limit externo)"
    scale_to_200: "Requiere paralelizaciÃ³n avanzada + caching"
    scale_to_500: "Requiere rediseÃ±o arquitectÃ³nico (abandonar conversacional)"
```

### 5. **Requerimientos No Funcionales Validados**

```yaml
non_functional_requirements:
  reliability:
    uptime_target: "> 99%"
    mtbf: "> 720 horas"
    mttr: "< 15 minutos"
    monitoring: "OpenTelemetry + Uptrace (free)"

  observability:
    logging:
      format: "JSON estructurado (structlog)"
      retention: "30 dÃ­as (compresiÃ³n + ILM)"
      fields_required:
        - "timestamp"
        - "agent"
        - "task"
        - "duration"
        - "cost_credits"
        - "model_used"

    metrics:
      latency: "P50, P95, P99 por agente"
      cost: "CrÃ©ditos y $ por anÃ¡lisis"
      errors: "Tasa de error por proveedor API"

    traces:
      tool: "OpenTelemetry SDK"
      backend: "Uptrace (1TB free storage)"
      sampling: "100% en producciÃ³n (bajo volumen)"

  security:
    authentication:
      github_pat: "Scopes mÃ­nimos (repo, read:org)"
      api_keys: ".env con .gitignore"
      rotation: "Cada 90 dÃ­as (automatizado)"

    data_privacy:
      pdf_handling: "Descargar â†’ Procesar â†’ Eliminar inmediato"
      no_persistence: "No guardar datos sensibles sin consentimiento"
      logs_sanitized: "URLs y parÃ¡metros sanitizados"

  resilience:
    patterns:
      - name: "Rate Limiting"
        implementation: "SlowAPI (token bucket)"
        config: "Por IP, por API key, por proveedor"

      - name: "Circuit Breaker"
        implementation: "PyBreaker"
        thresholds:
          failure_threshold: 5
          recovery_timeout: "60s"
          half_open_requests: 1

      - name: "Retry with Backoff"
        implementation: "Exponential backoff + jitter"
        config:
          max_retries: 3
          base_delay: "1s"
          max_delay: "30s"

      - name: "Timeout Management"
        config:
          api_calls: "30s"
          scraping: "60s"
          pdf_processing: "120s"
```

### 6. **Gates de Calidad Automatizados**

```yaml
quality_gates:
  mandatory_checks:
    - gate: "Structure Validation"
      when: "DespuÃ©s de cada agente"
      checks:
        - "Secciones obligatorias presentes"
        - "Formato Markdown vÃ¡lido"
        - "Sin placeholders (TODO, FIXME, XXX)"
        - "Longitud mÃ­nima cumplida"
      action_on_failure: "Retry con prompt especÃ­fico (max 2 intentos)"

    - gate: "Citation Validation"
      when: "DespuÃ©s de ContentSynthesizer"
      checks:
        - "Formato de citas correcto"
        - "Referencias bibliogrÃ¡ficas completas"
        - "No hay citas huÃ©rfanas"
        - "Orden alfabÃ©tico en bibliografÃ­a"
      action_on_failure: "Rerun con validaciÃ³n de BibTeX"

    - gate: "Consistency Check"
      when: "Antes de output final"
      checks:
        - "TerminologÃ­a consistente"
        - "No contradicciones entre secciones"
        - "Tono acadÃ©mico uniforme"
        - "Coherencia narrativa"
      action_on_failure: "Review manual + correcciÃ³n asistida"

    - gate: "Performance Check"
      when: "Durante ejecuciÃ³n"
      checks:
        - "Tiempo < SLA + 20%"
        - "CrÃ©ditos < presupuesto"
        - "Tasa error < 1%"
        - "Uso memoria < 80%"
      action_on_failure: "Log warning + alertar si crÃ­tico"

    - gate: "Cost Check"
      when: "Antes y despuÃ©s de cada agente"
      checks:
        - "CrÃ©ditos gastados vs proyectado"
        - "APIs externas dentro de lÃ­mites"
        - "No exceder presupuesto diario"
      action_on_failure: "Pausar pipeline + alertar + usar fallback"
```

### 7. **EvoluciÃ³n y Roadmap de Features**

```yaml
feature_roadmap:
  phase_1_mvp:
    timeline: "Sprint 1-4 (8 semanas)"
    features:
      - "6 agentes core funcionando"
      - "8 servidores MCP integrados"
      - "Pipeline secuencial completo"
      - "GeneraciÃ³n de 1 tesis ejemplo"
    success_criteria:
      - "Pipeline completo en 60-75 min"
      - "Presupuesto < $20/mes"
      - "Calidad acadÃ©mica validada"

  phase_2_optimization:
    timeline: "Sprint 5-8 (8 semanas)"
    features:
      - "ParalelizaciÃ³n de LiteratureResearcher"
      - "Caching distribuido (Valkey/Redis)"
      - "Dashboard de monitoreo (Uptrace)"
      - "Gates de calidad automatizados"
    success_criteria:
      - "Pipeline optimizado < 60 min"
      - "Uptime > 99%"
      - "100 anÃ¡lisis/mes sin intervenciÃ³n"

  phase_3_scale:
    timeline: "Sprint 9-12 (8 semanas)"
    features:
      - "Arquitectura basada en artefactos"
      - "Multi-tenancy (mÃºltiples usuarios)"
      - "API REST para integraciÃ³n externa"
      - "Marketplace de templates"
    success_criteria:
      - "Soportar 200 anÃ¡lisis/mes"
      - "Latencia P95 < SLA"
      - "5 clientes piloto activos"
```

---

## âœ… ConclusiÃ³n: Especificaciones Validadas y Listas para ImplementaciÃ³n

Estas especificaciones han sido **actualizadas con investigaciÃ³n real de Nov 2025**:

- âœ… **SLAs realistas** basados en benchmarks y limitaciones tÃ©cnicas reales
- âœ… **AsignaciÃ³n de modelos** optimizada para ROI mÃ¡ximo ($10-18/mes)
- âœ… **8 servidores MCP** 100% gratuitos con lÃ­mites verificados
- âœ… **Presupuesto validado** con 85% de buffer para escalabilidad
- âœ… **Gates de calidad** para garantizar outputs profesionales
- âœ… **Roadmap pragmÃ¡tico** alineado con capacidades reales

**El proyecto estÃ¡ LISTO para proceder a implementaciÃ³n con confianza del 95%.**

---

_Esta especificaciÃ³n define el QUÃ‰ y el POR QUÃ‰. El plan tÃ©cnico define el CÃ“MO._
